/*! \page install_linux Installing ISCE on Centos 7.5 / Ubuntu 18.04

\tableofcontents

ISCE has the following dependencies
<ol>
<li> C++ compiler - gcc-6 or above
<li> Python 3.6 or above
<li> Numpy and Cython
<li> GDAL 2.3 or above with Python bindings
<li> HDF5 1.10.2 or above with h5py
<li> cmake 3.12 or above
<li> CUDA 9.0 or above (for GPU-based processing)
</ol>

Optional dependencies for unit testing and documentation generation are 
<ol>
<li> pytest (for Python unit tests)
<li> sphinx (for documenting Python code)
<li> doxygen (for documenting C++ code)
</ol>

As of Jan 2020, Centos 7.5 is the operational OS for the NISAR processing system and this is <br> 
probably the most tested set of instructions. The instructions for Centos 7.5 / Ubuntu 18.04 <br>
are more or less the same except for the parts specific to using the standard package managers <br>
to install compilers and some basic packages. 

We will install all dependencies under a folder called ${ISCEHOME} in the instructions below. <br>
Our overall strategy for directory layouts is as follows:

<table>
<caption id="directory_structure">Assumed directory structure for installation</caption>
<tr><th>Path<th>Description
<tr><td>${ISCEHOME}/python/miniconda3<td>Miniconda3 installation directory
<tr><td>${ISCEHOME}/tools/isce/src <td>git checkout location/ unpacked tarball location of ISCE source
<tr><td>${ISCEHOME}/tools/isce/build <td>cmake build location
<tr><td>${ISCEHOME}/tools/isce/install <td>cmake install location 
<tr><td>${ISCEHOME}/tools/gcc7<td>Directory for gcc7 compiled from source (Only for Centos 7.5)
</table>


Note that ${ISCEHOME} in these can be any directory on your machine. You can even use your home <br>
folder as the base for your directory structure.

\section linuxpack Installing packages using builtin package manager

\subsection centosyum yum on Centos 7.5

This section only applies to installation on Centos 7.5. The following packages and their dependencies <br>
should be installed using "yum".
<ol>
<li>curl
<li>sudo
<li>bzip2
<li>zip
</ol>

If CUDA support is desired, install the following set of packages with yum as well:
<ol>
<li>cuda-libraries-dev-10.1 
<li>cuda-nvml-dev-10.1
<li>cuda-minimal-build-10.1
<li>cuda-command-line-tools-10.1
</ol>


\subsubsection centosgcc7 gcc7 on Centos7.5
Centos 7.5 is a fairly old distribution and attempts to guarantee backward compatibility. 
As a result, the gcc/g++ compilers that are included with this distribution do not support <br>
gcc's dual ABI. Hence, you will have to build a gcc compiler ( version > 6) manually for use. 

<ol>
<li> If you are within JPL, you can get a version of gcc7 here: 
<a href="https://github-fn.jpl.nasa.gov/NISAR-ADT/gcc7/releases/download/v0.0.1/gcc7.tar.gz"> https://github-fn.jpl.nasa.gov/NISAR-ADT/gcc7/releases/download/v0.0.1/gcc7.tar.gz </a>. 


<li> Untar the contents of this file to ${ISCEHOME}/tools/gcc7 
\verbatim
tar xzv gcc7.tar.gz -C ${ISCEHOME}/tools
\endverbatim


\subsection ubuntuapt apt-get on Ubuntu 18.04

This section only applies to installation on Ubuntu 18.04. The following packages and their <br>
dependencies should be installed using "apt-get".

<ol>
<li>gnupg2
<li>curl
<li>ca-certificates
<li>bzip2
<li>zip
<li>gcc-6
<li>g++-6
</ol>

If CUDA support is desired, install the following set of packages with apt-get as well:
<ol>
<li>nvidia-cuda-toolkit
</ol>

\section conda Installing Anaconda and Python packages

In this set of instructions, we rely on <a href="https://anaconda.org/">Anaconda</a> for installing <br>
Python dependencies. We will install Python3 to the location ${ISCEHOME}/python/miniconda3. 

<ol>
<li> We will list all the required packages in a text file called "requirements.txt" located under ${ISCEHOME}/python. <br>
The contents of the requirements.txt file is shown below:

\verbatim

cmake
cython
gdal
git
h5py
libgdal
pytest
numpy
fftw
scipy
pyproj
matplotlib
pandas
sphinx

\endverbatim

<li> We can then install Anaconda and these requirements as shown below:
\code{.sh}
> cd ${ISCEHOME}/python
> curl -sSL https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -o miniconda.sh
> bash miniconda.sh -b -p ${ISCEHOME}/python/miniconda3
> touch ${ISCEHOME}/python/miniconda3/conda-meta/pinned
> export PATH=${ISCEHOME}/python/miniconda3/bin:$PATH
> export LD_LIBRARY_PATH=${ISCEHOME}/python/miniconda3/lib:$LD_LIBRARY_PATH
> conda config --set show_channel_urls True
> conda update --all
> conda install --file ${ISCEHOME}/python/requirements.txt
\endcode


<li> (Optional) On some systems, it may be necessary to activate the conda root environment <br>
in order to export important environment variables used by make, cmake, etc. <br>
To activate the environment, use:
\verbatim
> . ${ISCEHOME}/python/miniconda3/bin/activate root
\endverbatim
</ol>

\section isce3linux Install ISCE from source

In this section we will walk through the directory setup and build system instructions for installing ISCE.
ISCE can be built with 2 different build systems 
<ol>
<li> <a href="https://github.com/aivazis/config">mm</a>
<li><a href="https://cmake.org/">cmake</a>. 
</ol>

In this set of instructions, we focus on cmake as it is already available via standard package managers.

\subsection isce3targit Step 1: Get latest version of ISCE source

\subsubsection isce3git  Option 1: Checkout latest version from git

<ol>
<li> Ensure that you are in the source folder
\code{.sh}
> cd ${ISCEHOME}/tools/isce/src
\endcode
<li> Check out the latest version of the source code from git
\code{.sh}
> git clone https://github-fn.jpl.nasa.gov/isce-3/isce
\endcode
<li> Ensure you are building the branch that you want to use. <br>
For example, if you want to build the <b>develop</b> branch
\code{.sh}
> cd isce
> git checkout develop
\endcode
</ol>


\subsubsection isce3tar Option 2: Get the latest tarball 

<ol>
<li> Ensure that you are in the source folder
\code{.sh}
> cd ${ISCEHOME}/tools/isce/src
\endcode
<li> Unpack the tarball.
\code{.sh}
> tar xjbf isce.tar.bz2
\endcode
</ol>


\subsection isce3build Step 2: Build the software

<ol>
<li> For our cmake build, we follow the practice of building outside of the source parent directory.<br>
To that end, we first create a temporary build directory:
\code{.sh}
> cd ${ISCEHOME}/tools/isce
> mkdir build
> cd build
\endcode

<li> Ensure that you have activated the scl environment (Centos), conda and set <br>
environment variables needed by pyre following instructions provided above. 

Note: for some operating systems, if you wish to build the CUDA extensions, you may need to run
\code{.sh}
export CUDACXX=/usr/local/cuda/bin/nvcc
\endcode

<li> Run cmake with the correct inputs and compiler flags 
\code{.sh}

> CC=gcc CXX=g++ cmake -DCMAKE_INSTALL_PREFIX=${ISCEHOME}/tools/isce/install ${ISCEHOME}/tools/isce/src/isce

\endcode

or 

\code{.sh}

> CC=${ISCEHOME}/tools/gcc7/bin/gcc CXX=${ISCEHOME}/tools/gcc7/bin/g++ \
  cmake -DCMAKE_INSTALL_PREFIX=${ISCEHOME}/tools/isce/install \
        ${ISCEHOME}/tools/isce/src/isce

\endcode


Other optional arguments can be added to the cmake line
<table>
    <caption id="cmake_options">Additional cmake options</caption>
    <tr><th>Option <th>Description
    <tr><td>-DWITH_CUDA=ON  <td>Build with CUDA support (will need CUDA libraries installed)
    <tr><td rowspan="3">-DMEMORY_CHECK_COMMAND=PATH_TO_VALGRIND_EXECUTABLE \<br>
                        -DMEMORYCHECK_COMMAND_OPTIONS="--trace-children=yes --leak-check=full --track-origins=yes" \<br>
                        -DCMAKE_BUILD_TYPE=Debug<td>  
    <tr><td>Run tests with "-T memcheck" to check for memory leaks.
    <tr><td>valgrind needs to be installed.
    <tr><td>-DPYTHON_EXECUTABLE:FILENAME=<path_to_python_exe><td>Pass this argument if installing to a 
    python virtual environment
    <tr><td>-DCMAKE_BUILD_TYPE=RelWithDebInfo<td>Build with optimization flags with release.
    Default is to build in debug mode
</table>

Following env variables can also be used to control cmake behavior. Use these settings
if cmake fails to identify the right compilers or install locations of dependencies.
<table>
    <caption id="cmake_env_options">Additional environment variables impacting cmake</caption>
    <tr><th>Variable<th>Description
    <tr><td>CC <td>Path to the C compiler
    <tr><td>CXX <td>Path to the C++ compiler
    <tr><td>GDAL_ROOT <td> Path to location of gdal installation. With anaconda, ${ISCEHOME}/python/miniconda3.
</table>

<li> Build the software
\code{.sh}
> make VERBOSE=ON
\endcode

<li> Run the unit tests to ensure that software was built correctly
\code{.sh}
> ctest
\endcode
</ol>

\subsection isce3install Step 3: Install and set environment variables

<ol>
<li> Ensure that you are in the build folder
\code{.sh}
> cd ${ISCEHOME}/tools/isce/build
\endcode 

<li> Install the software
\code{.sh}
> make install
\endcode

<li> Setup the environment variables.

<table>
    <caption id="env_vars">Environment variables to set after installing ISCE</caption>
    <tr><th>Variable<th>Setting<th>Description
    <tr><td>PATH<td>$PATH:${ISCEHOME}/tools/isce/install/bin<td>For executables installed by ISCE
    <tr><td>PYTHONPATH<td>$PYTHONPATH:${ISCEHOME}/tools/isce/install/packages<td>ISCE python package
    <tr><td>LD_LIBRARY_PATH<td>$LD_LIBRARY_PATH:${ISCEHOME}/tools/isce/install/lib<td>Shared libraries built by ISCE
</table>

We also recommend setting these environment variables in your appropriate `.bashrc` or `.bash_profile` <br>
file to avoid having to set them for each new session. For example:

\code{.sh}
# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
. ~/.bashrc
fi

# User specific environment and startup programs

# miniconda3
export PATH=${ISCEHOME}/python/miniconda3/bin:$PATH
export LD_LIBRARY_PATH=${ISCEHOME}/python/miniconda3/lib:$LD_LIBRARY_PATH

# cuda
export CUDACXX=/usr/local/cuda/bin/nvcc

# isce
export PATH=$PATH:${ISCEHOME}/tools/isce/install/bin
export PYTHONPATH=$PYTHONPATH:${ISCEHOME}/tools/isce/install/packages
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${ISCEHOME}/tools/isce/install/lib
\endcode

</ol>

*/
